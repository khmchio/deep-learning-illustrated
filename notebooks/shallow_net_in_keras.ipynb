{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Neural Network in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a shallow neural network to classify MNIST digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/shallow_net_in_keras.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that there are 60,000 labels indiating what digit each of the 60,000 training images contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST data where X represent the data we're feeding into the model and y is used for the labelled ouput that we're training the model to predict.\n",
    "* *Training Labels*: Training labels are the known outputs (or \"targets\") corresponding to the training data inputs. In supervised learning tasks, such as classification or regression, the training labels represent the ground truth values that the model aims to learn to predict. During the training process, the model adjusts its parameters to minimize the discrepancy between its predictions and the actual training labels.\n",
    "\n",
    "* *Validation Labels*: Validation labels, on the other hand, are also known outputs, but they are used for evaluating the performance of the trained model during the training process. After training the model using the training dataset, the model's performance is assessed using the validation dataset. The validation labels help assess how well the model generalizes to unseen data and whether it suffers from overfitting (i.e., performing well on the training data but poorly on new data). The validation dataset is typically separate from the training dataset to provide an unbiased estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that there are 60,000 images in our training data set, each is a 28x28 matrix of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aab2c76bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap='Greys')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Below examines the shape of the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10,000 28x28 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aab5e35fa90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aab2c54a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_valid[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
       "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
       "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
       "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
       "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
       "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
       "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show matrix of integers representing the handingwriting is primarily zero (whitespace). You might make it out that the digit is seven with the higest integers (254, 255) representing the black core of the handwritten figure and the outline of the figure (composed of intermediate integers) fading toward white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label / output is 7 - same as what we thought the output would be!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess model inputs X*\n",
    "\n",
    "We won't be preprocessing the images by apply functions to,say, extract features that provide hints to our artificial neural network. We will simply be rearranging the *shape* of the data so that they match up with the shapes of the input and output layers of the network.\n",
    "\n",
    "Simultaneoulsy, we will convert the pixel darknesses from integers to single-precision float values, in preparation to divide these values by 255 so that they can range from 0 to 1.\n",
    "\n",
    "- Single-precision floating-point values(\"float32\" - stored using 32bit/4 bytes of memeory ) refer to a data type used to represent decimal numbers with a limited precision (around 7 decimal digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_valid = X_valid.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.32941177,  0.72549021,  0.62352943,\n",
       "        0.59215689,  0.23529412,  0.14117648,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.87058824,  0.99607843,  0.99607843,  0.99607843,  0.99607843,\n",
       "        0.94509804,  0.7764706 ,  0.7764706 ,  0.7764706 ,  0.7764706 ,\n",
       "        0.7764706 ,  0.7764706 ,  0.7764706 ,  0.7764706 ,  0.66666669,\n",
       "        0.20392157,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.26274511,  0.44705883,\n",
       "        0.28235295,  0.44705883,  0.63921571,  0.89019608,  0.99607843,\n",
       "        0.88235295,  0.99607843,  0.99607843,  0.99607843,  0.98039216,\n",
       "        0.89803922,  0.99607843,  0.99607843,  0.54901963,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.06666667,  0.25882354,  0.05490196,  0.26274511,\n",
       "        0.26274511,  0.26274511,  0.23137255,  0.08235294,  0.9254902 ,\n",
       "        0.99607843,  0.41568628,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.32549021,  0.99215686,  0.81960785,  0.07058824,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.08627451,  0.9137255 ,\n",
       "        1.        ,  0.32549021,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.50588238,  0.99607843,  0.93333334,  0.17254902,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.23137255,  0.97647059,\n",
       "        0.99607843,  0.24313726,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.52156866,  0.99607843,  0.73333335,  0.01960784,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.03529412,  0.80392158,\n",
       "        0.97254902,  0.22745098,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.49411765,  0.99607843,  0.71372551,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.29411766,  0.98431373,\n",
       "        0.94117647,  0.22352941,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.07450981,  0.86666667,  0.99607843,  0.65098041,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.01176471,  0.79607844,  0.99607843,\n",
       "        0.85882354,  0.13725491,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.14901961,  0.99607843,  0.99607843,  0.3019608 ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.12156863,  0.87843138,  0.99607843,\n",
       "        0.4509804 ,  0.00392157,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.52156866,  0.99607843,  0.99607843,  0.20392157,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.23921569,  0.94901961,  0.99607843,\n",
       "        0.99607843,  0.20392157,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.47450981,  0.99607843,  0.99607843,  0.85882354,  0.15686275,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.47450981,  0.99607843,\n",
       "        0.81176472,  0.07058824,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preprocess labels y*\n",
    "\n",
    "Convert them from integers into *one-hot encodings*.\n",
    "* One-hot encodings is a method of representing categorical variables as binary vectors (i.e., a vector of 0s and 1s), where each category corresponds to a unique position in the vector. Each instance in the dataset is then represented by one of these binary vectors, where a 1 indicating the presence of a particular category and 0s elsewhere. \n",
    " * Suppose you have a categorical variable \"Color\" with three unique categories: \"Red\", \"Green\", and \"Blue\".\n",
    " * \"Red\" is encoded as [1, 0, 0]\n",
    " * \"Green\" is encoded as [0, 1, 0]\n",
    " * \"Blue\" is encoded as [0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ten possible digits (0 to 9) so we set `n_classes` = 10.\n",
    "Next, we use a convenient utility function `to_categorical` (which is provided within the Keras library) to transform both the training and validation labels from integers to the one-hot-format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output shows how label *Seven* is represented. \n",
    "\n",
    "In such one-hot encoding, the label *zero* would be be represented by 1 in the first position, *one* represented by 1 in the second position.\n",
    "\n",
    "We arrange the labels with such one-hot encoding so that they line up with the 10 probabilities being output by the final layer of our artifical neural network. If the input image is a handwritten *seven* then a perfectly-trainned network would output a probability of 1.00 that it is a seven and a probability of 0.00 for each of the the other nine classes of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In architecting the artificial neural net itself, we first:\n",
    "* Institaite the simplest type of neural-network model, the *sequential* type\n",
    "* Then, we `add()` the attributes of our one hidden layer\n",
    " * which consists of 64 sigmoid-type artificial neurons in the general-purpose, fully-connected arrangement defined by the `Dense()` method) to our *model* object \n",
    " * as well as the shape of our input layer (our reshaped one-dimenstional array of length 28 x 28 =784)\n",
    "* Last, we specify the output layer and its parameters: 10 artifical neurons of the *softmax* variety correspnding to the ten probability for each of the ten possible digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *sigmoid-type* neurons: Takes a real-valued input and squashes it into a range between 0 and 1. \n",
    "\n",
    "* *softmax* neurons: Takes a vector of real-valued inputs and squashes them to a probability distribution over multiple classes. It transforms each element of the input vector into a probability between 0 and 1. The sum of all probabilities equals 1, representing a probability distribution over multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50176"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50240"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*784)+64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10*64)+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Keras code to train our shallow neural network:\n",
    "1. The `fit()` method of our model object enables us to train our artificial neural network with the training images `X_train` as inputs and their associated labels `y_train` as the desired outputs.\n",
    "2. As the network trains, the `fit()` method also provides us with the option to evaluate the performance of our network by passing our validation data `X_valid` and `y_valid` into the `validation_data` parameter.\n",
    "3. With machine learning, and especially with deep learning, it is commonplace to train our model on the same data multiple times. One pass through all of our training data (60,000 images in the current case) is called one *epoch* of training. By setting the epochs parameter to 200, we cycle through all 60,000 training images two hundred separate times.\n",
    "4. By setting `verbose` to 1, `model.fit()` will provide us with plenty of feedback as we train. At the moment, we’ll focus on the `val_acc` statistic output following each epoch of training. *Validation accuracy* is the proportion of the 10,000 handwritten images in `X_valid` where the network’s highest probability in the output layercorresponds to the correct digit as per the labels in `y_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.0919 - acc: 0.0515 - val_loss: 0.0915 - val_acc: 0.0657\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.0912 - acc: 0.0747 - val_loss: 0.0909 - val_acc: 0.0894\n",
      "Epoch 3/200\n",
      " 6272/60000 [==>...........................] - ETA: 13s - loss: 0.0909 - acc: 0.0917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-fe7445d47c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the first epoch of training, we observe val_acc: 0.1010. \n",
    "* That is, 10.1% of the images from the held­out validation dataset were correctly classified by our shallow architecture. Given that there are ten classes of handwritten digits, we’d expect a random process to guess ten percent of the digits correctly by chance, so this is not an impressive result. \n",
    "* As the network continues to train, however, the results improve. After ten epochs of training, it is correctly classifying 36.5% of the validation images— far better than would be expected by chance! And this is only the beginning: \n",
    "* After 200 epochs, the network’s improvements appears to be plateauing as it approaches 86% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02861827013194561, 0.856]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
